# ASSVA â€” Solar Racing Driver Assist

Real-time driver assistance system for a solar racing car. Streams video from a Raspberry Pi camera, runs TFLite object detection (cones & potholes), and displays detection overlays, telemetry, and GPS on an Android tablet.

## Architecture

```mermaid
flowchart TB
    subgraph PI["ðŸŸ¢ Raspberry Pi"]
        direction LR
        CAM["ðŸ“· Camera"] --> OCV["OpenCV"] --> TFL["TFLite\nInference"] --> SRV["aiohttp\nServer"]
    end

    SRV -- "/stream Â· MJPEG" --> APP
    SRV -- "/detections Â· JSON" --> APP
    APP -- "/set_model" --> SRV

    subgraph APP["ðŸ“± Android App Â· React Native"]
        direction LR
        VID["MjpegView"] ~~~ DET["DetectionOverlay"] ~~~ MAP["MapDashboard"]
        CTL["ControlPanel"] ~~~ TEL["TelemetryDashboard"] ~~~ SOL["SolarOverlay"]
    end
```

## Quick Start

### Pi Server

```bash
cd pi

# Create venv and install dependencies
python3 -m venv venv
source venv/bin/activate
pip install aiohttp opencv-python-headless numpy ai-edge-litert

# Place models
mkdir -p models
# Copy cone_detect.tflite and pothole_detect.tflite into models/

# Run server
python3 server.py
```

The server runs on `http://0.0.0.0:8080` with these endpoints:

| Endpoint | Method | Description |
|---|---|---|
| `/stream` | GET | MJPEG video stream |
| `/frame` | GET | Single JPEG snapshot |
| `/detections` | GET | Latest detection results (JSON) |
| `/set_model` | POST | Switch model: `{"model": "cone\|pothole\|off"}` |
| `/status` | GET | Health check + model status |
| `/debug` | GET | Raw model output for debugging |

### Android App

```bash
# Install dependencies
npm install

# Build and run on connected Android device
npx expo run:android
```

> **Note:** The app connects to the Pi at `10.165.71.121:8080`. Update `PI_URL` in `src/App.tsx` and `src/services/InferenceClient.ts` if your Pi has a different IP.

## Project Structure

```
â”œâ”€â”€ pi/                          # Raspberry Pi server
â”‚   â”œâ”€â”€ server.py                # MJPEG + TFLite inference server
â”‚   â””â”€â”€ models/                  # TFLite model files
â”‚       â”œâ”€â”€ cone_detect.tflite
â”‚       â””â”€â”€ pothole_detect.tflite
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ App.tsx                  # Main app â€” video + overlays + dashboard
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ MjpegView.tsx        # WebView-based MJPEG viewer
â”‚   â”‚   â”œâ”€â”€ DetectionOverlay.tsx  # SVG bounding boxes + collision warning
â”‚   â”‚   â”œâ”€â”€ ControlPanel.tsx     # Cone/Pothole/Off model toggle
â”‚   â”‚   â”œâ”€â”€ TelemetryDashboard.tsx # Speed, battery, power, range
â”‚   â”‚   â””â”€â”€ MapDashboard.tsx     # GPS map with path history
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ InferenceClient.ts   # Polls /detections, sends /set_model
â”‚   â””â”€â”€ store/
â”‚       â””â”€â”€ useAppStore.ts       # Zustand state (detections, telemetry, etc)
â”œâ”€â”€ __tests__/                   # Integration tests
â”‚   â”œâ”€â”€ controls.integration.test.ts
â”‚   â”œâ”€â”€ telemetry.integration.test.ts
â”‚   â”œâ”€â”€ maps.integration.test.ts
â”‚   â””â”€â”€ webrtc.integration.test.ts  # (inference tests)
â””â”€â”€ package.json
```

## Features

- **MJPEG Video Stream** â€” Low-latency camera feed via HTTP
- **TFLite Inference** â€” Cone and pothole detection on the Pi
- **Detection Overlay** â€” Bounding boxes drawn over the video in real-time
- **Collision Warning** â€” Flashing âš  CONE AHEAD when a cone is in the danger zone for 3+ consecutive frames
- **Model Switching** â€” Toggle between cone, pothole, or off from the app
- **Telemetry** â€” Speed, battery, power consumption, range display
- **GPS Map** â€” Live position with path history

## Models

| Model | Input Size | Format | Type |
|---|---|---|---|
| Cone Detection | 320Ã—320 | SSD `[x1,y1,x2,y2,conf,class]` | uint8 quantized |
| Pothole Detection | 256Ã—256 | SSD `[x1,y1,x2,y2,conf,class]` | float32 |

## Testing

```bash
npm test
```

## Network Setup

The Pi connects to the Android phone's Wi-Fi hotspot via Ethernet. The phone runs the app and communicates with the Pi over standard HTTP.

```mermaid
flowchart TD
    HOTSPOT["ðŸ“¶ Phone Wi-Fi Hotspot\n10.165.71.x"] -->|Ethernet| PI["ðŸŸ¢ Raspberry Pi\n10.165.71.121"]
    HOTSPOT -->|Localhost| APP["ðŸ“± Phone App\nDisplay + Controls"]
    PI <-->|HTTP| APP
```
